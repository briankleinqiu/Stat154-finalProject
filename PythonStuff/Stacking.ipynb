{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import pickle \n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "\n",
    "def run(data, y):\n",
    "    X = data\n",
    "    Y = y\n",
    "    \n",
    "    # The DEV SET will be used for all training and validation purposes\n",
    "    # The TEST SET will never be used for training, it is the unseen set.\n",
    "    dev_cutoff = len(Y) * 4/5\n",
    "    X_dev = X[:dev_cutoff]\n",
    "    Y_dev = Y[:dev_cutoff]\n",
    "    X_test = X[dev_cutoff:]\n",
    "    Y_test = Y[dev_cutoff:]\n",
    "    \n",
    "    n_trees = 10\n",
    "    n_folds = 5\n",
    "    \n",
    "    # Our level 0 classifiers\n",
    "    clfs = [\n",
    "        RandomForestClassifier(n_estimators = n_trees, criterion = 'gini'),\n",
    "        ExtraTreesClassifier(n_estimators = n_trees * 2, criterion = 'gini'),\n",
    "        GradientBoostingClassifier(n_estimators = n_trees),\n",
    "    ]\n",
    "    \n",
    "    # Ready for cross validation\n",
    "    skf = list(StratifiedKFold(Y_dev, n_folds))\n",
    "    \n",
    "    # Pre-allocate the data\n",
    "    blend_train = np.zeros((X_dev.shape[0], len(clfs))) # Number of training data x Number of classifiers\n",
    "    blend_test = np.zeros((X_test.shape[0], len(clfs))) # Number of testing data x Number of classifiers\n",
    "    \n",
    "    print 'X_test.shape = %s' % (str(X_test.shape))\n",
    "    print 'blend_train.shape = %s' % (str(blend_train.shape))\n",
    "    print 'blend_test.shape = %s' % (str(blend_test.shape))\n",
    "    \n",
    "    # For each classifier, we train the number of fold times (=len(skf))\n",
    "    for j, clf in enumerate(clfs):\n",
    "        print 'Training classifier [%s]' % (j)\n",
    "        blend_test_j = np.zeros((X_test.shape[0], len(skf))) # Number of testing data x Number of folds , we will take the mean of the predictions later\n",
    "        for i, (train_index, cv_index) in enumerate(skf):\n",
    "            print 'Fold [%s]' % (i)\n",
    "            \n",
    "            # This is the training and validation set\n",
    "            X_train = X_dev[train_index]\n",
    "            Y_train = Y_dev[train_index]\n",
    "            X_cv = X_dev[cv_index]\n",
    "            Y_cv = Y_dev[cv_index]\n",
    "            \n",
    "            clf.fit(X_train, Y_train)\n",
    "            \n",
    "            # This output will be the basis for our blended classifier to train against,\n",
    "            # which is also the output of our classifiers\n",
    "            blend_train[cv_index, j] = clf.predict(X_cv)\n",
    "            blend_test_j[:, i] = clf.predict(X_test)\n",
    "        # Take the mean of the predictions of the cross validation set\n",
    "        blend_test[:, j] = blend_test_j.mean(1)\n",
    "    \n",
    "    print 'Y_dev.shape = %s' % (Y_dev.shape)\n",
    "    \n",
    "    # Start blending!\n",
    "    bclf = LogisticRegression()\n",
    "    bclf.fit(blend_train, Y_dev)\n",
    "    \n",
    "    # Predict now\n",
    "    Y_test_predict = bclf.predict(blend_test)\n",
    "    score = metrics.accuracy_score(Y_test, Y_test_predict)\n",
    "    print 'Accuracy = %s' % (score)\n",
    "    \n",
    "    joblib.dump(bclf, 'stacked_log.pkl')\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.sparse import hstack\n",
    "X_train = np.load(\"Data/X_train.npy\")[()]\n",
    "y_train = np.load(\"Data/y_train.npy\")[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
